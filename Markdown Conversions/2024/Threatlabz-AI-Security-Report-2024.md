Zscaler ThreatLabz2024 AI Security ReportThe AI revolution has arrived. Discover key trends, risks, and best practices in enterpriseAI adoption, with insights into AI\-driven threats and key strategies to defend against them.2024 Zscaler, Inc. All rights reserved.2024 Zscaler, Inc. All rights reserved.Contents03Executive Summary04Key Findings05Key GenAI and ML Usage Trends05 AI transactions continue to accelerate06 Enterprises are blocking more AI transactions than ever07 Industry AI breakdown09 Healthcare and AI10 Finance11 Government12 Manufacturing13 Education and AI14 ChatGPT usage trends15 AI usage by countryRegional breakdown: EMEARegional breakdown: APAC23 AI\-driven malware and ransomware across the attack chain24 AI worm attacks and viral AI jailbreaking25 AI and US elections26All Eyes on AI Regulations26 United States27 European Union28AI Threat Predictions31Case Study: How to Securely Enable ChatGPTin the Enterprise31 5 Steps to integrate and secure generative AI tools33How Zscaler Delivers AI \+ Zero Trust andSecures Generative AI33 The key to AI\-driven cybersecurity: high\-quality data at scale34 Leveraging AI across the attack chain18Enterprise AI Risk and Real\-World Threat Scenarios35 Summary of Zscalers AI\-infused offerings18 Enabling AI in the enterprise: top 3 risks36 Enabling the enterprise AI transition: the control is in your hands20 AI\-driven threat scenariosAI impersonation: deepfakes, misinformation, and more21 AI\-generated phishing campaignsFrom query to crime: creating a phishing login page using ChatGPT22 Dark chatbots: uncovering WormGPT and FraudGPT on the dark web37Appendix37ThreatLabz research methodology37About Zscaler ThreatLabz022024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024Executive SummaryAI is more than a pioneering innovationits now business as usual. As generative 
AI tools like ChatGPT transform business in large and small ways, AI is being woven 
deep into the fabric of enterprise life. However, questions about how to securely 
adopt these AI tools while defending against AI\-driven threats are not settled.Enterprises are rapidly adopting AI and ML tools across departments likeDrawing on more than 18 billion transactions from April 2023 to Januaryengineering, IT marketing, finance, customer success, and more. Yet,2024 across the Zscaler Zero Trust Exchange, ThreatLabz analyzedthey must balance the numerous risks that come with AI tools to reaphow enterprises are using AI and ML tools today. These insights revealtheir fullest rewards. Indeed, to unlock the transformative potential of AI, 
enterprises must enable secure controls to protect their data, prevent thekey trends across business sectors and geographies in how enterprises 
are adapting to the shifting AI landscape and securing their AI tools.leakage of sensitive information, mitigate Shadow AI sprawl, and ensurethe quality of AI data.These AI risks to enterprises are bidirectional: outside enterprise walls, AI 
has become a driving force for cyberthreats. Indeed, AI tools are allowing 
cybercriminals and nation state\-sponsored threat actors to launchsophisticated attacks, more quickly, and at greater scale. Despite this, AIholds promise as a key piece of the cyber defense puzzle as enterprisesgrapple with a dynamic threat landscape.Throughout, youll find insights into top\-of\-mind AI topics includingbusiness risk, AI\-driven threat scenarios and adversary tactics,regulatory considerations, and predictions for the AI landscape in 2024and beyond.Just as critically, this report offers best practices on two fronts: howenterprises can securely embrace generative AI transformation whileprotecting critical data, and how AI\-powered tools are working todeliver layered, zero trust security to face the new landscape of AI\-The ThreatLabz 2024 AI Security Report offers key insights into thesedriven threats.critical AI challenges and opportunities.032024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024Key FindingsAIML tool usage skyrocketed by 594\.82%, rising from 
521 million AIML\-driven transactions in April 2023 to 3\.1 
billion monthly by January 2024\.Enterprises are blocking 18\.5% of all AIML 
transactionsa 577% increase in blocked transactions over 
nine monthsreflecting growing concerns around AI data 
security and companies reluctance to establish AI policies.The most widely used AI applications by transaction 
volume are ChatGPT, Drift, OpenAI Writer, and 
LivePerson. The top three blocked applications by 
transaction volume are ChatGPT, OpenAI, and Fraud.net.The top 5 countries generating the most AI and ML 
transactions are the US, India, the UK, Australia, and Japan.Manufacturing generates the most AI traffic with 20\.9% 
of all AIML transactions in the Zscaler cloud, followed 
by Finance and Insurance (19\.9%) and Services (16\.8%).Enterprises are sending significant volumes of data to AI 
tools, with a total of 569 TB exchanged between AIML 
applications between September 2023 and January 2024\.ChatGPT usage continues to soar, with 634\.1% growth, 
even though it is also the most\-blocked AI application 
by enterprises, based on Zscaler cloud insights.AI is empowering threat actors in unprecedented ways, 
including for AI\-driven phishing campaigns, deepfakes 
and social engineering attacks, polymorphic ransomware, 
enterprise attack surface discovery, automated exploit 
generation, and more.NOTE:The Zscaler Zero Trust Exchange tracks ChatGPT transactions independently from other OpenAI transactions at large.042024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024Key GenAI and ML 
Usage TrendsThe enterprise AI revolution is far from its peak. 
Enterprise AI transactions have surged by
nearly 600% and show no signs of slowing.
Still, blocked transactions to AI apps have also 
risen by 577%.4000M3000M2000M1000Ms
n
o
i
t
c
a
s
n
a
r
T0MAI and ML Transaction TrendsMayJulSepNovJanMonthFIGURE 1 AI transactions from April 2023 to January 2024AI transactions continue
to accelerateFrom April 2023 to January 2024, enterprise AI and ML transactions grew by nearly600%, rising to more than 3 billion monthly transactions across the Zero Trust Exchange inJanuary. This underscores the fact that, despite a rising number of security incidents anddata risks associated with enterprise AI adoption, its transformative potential is too greatto ignore. Note that while AI transactions saw a brief lull over the December holidays,transactions continued at an even greater pace at the start of 2024\.Even as AI applications proliferate, however, the majority of AI transactions are beingdriven by a relatively small set of market\-leading AI tools. Overall, ChatGPT accounts for 
more than half of all AI and ML transactions, while the OpenAI application itself comesin third place, with 7\.82% of all transactions. Meanwhile, Drift, the popular AI\-poweredchatbot, generated nearly one\-fifth of enterprise AI traffic (the LivePerson and BoldChatEnterprise chatbots also breached the top apps in spots 5 and 6\). Meanwhile, Writerremains a favored generative AI tool in the creation of written enterprise content, such asmarketing materials. Finally, Otter, an AI transcription tool often used in video calls, drives 
a significant portion of AI traffic.Top AI Applications18\.51%52\.23%ChatGPTDriftOpenAIWriterLivePersonBoldChat EnterprisesOtter AI7\.82%3\.86%2\.78%2\.06%1\.29%FIGURE 2 Top AI applications by transaction volume052024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSData transferred by AIML Traffic \[Sep 2023\-Jan 2024]Fotor
0\.8%
VEED
4\.4%
OpenAI
4\.7%ChatGPT
27\.9%Hugging Face
57\.1%FIGURE 3 Top AIML apps by the percentage of total data transferredBlocked AI transaction trends \[Apr 2023 \- Jan 2024]800M600M400M200Ms
n
o
i
t
c
a
s
n
a
r
T0MMayJulSepMonthNovJanFIGURE 4 Number of AIML transactions blocked over timeMeanwhile, the volumes of data that enterprises send and receive from AI tools addsnuance to these trends. Hugging Face, the open\-source AI developer platform oftendescribed as the GitHub of AI, accounts for nearly 60% of enterprise data transferredby AI tools. Since Hugging Face allows users to host and train AI models, it makes sensethat it captures significant data volumes from enterprise users.While ChatGPT and OpenAI make expected appearances on this list, two notableadditions are Veedan AI video editor often used to add subtitles, imagery, and othertext to videosand Fotor, a tool used to generate AI images, among other uses. Sincevideos and images entail large file sizes compared to other kinds of requests, its notsurprising to see these two applications represented.Enterprises are blocking more
AI transactions than everEven as enterprise AI adoption continues to surge, organizations are increasingly blockingAI and ML transactions because of data and security concerns. Today, enterprises block18\.5% of all AI transactions, a 577% increase from April to January, for a total of morethan 2\.6 billion blocked transactions.Some of the most popular AI tools are also the most blocked. Indeed, ChatGPT holdsthe distinction of being both the most\-used and most\-blocked AI application. Thisindicates that despiteor even because ofthe popularity of these tools, enterprisesare working actively to secure their use against data loss and privacy concerns. Anothernotable trend is that bing.com, which has an AI\-enabled Copilot functionality, is blockedfrom April to January. In fact, bing.com accounts for 25\.02% of all blocked AI and MLdomain transactions.062024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSTO PM OST\-TO PB LO CKE DB LO CKE DA ITO OL SA ID OMAIN S01ChatGPT02OpenAI03Fraud.net01Bing.com02Divo.ai03Drift.com04Forethought04Quillbot.com05Hugging Face05Compose.ai06ChatBot07Aivo08Neeva06Openai.com07Qortex.ai08Sider.ai09infeedo.ai09Tabnine.com10Jasper10securiti.aiShare of AI Transactions by Industry VerticalEducation
1\.7%
Energy, Oil \& Gas
1\.7%
Government
3\.3%
Retail \& Wholesale
4\.9%
Healthcare
5\.5%Others
7\.6%Technology
15\.6%Manufacturing
20\.9%Finance \&
Insurance
19\.9%Services
16\.8%FIGURE 6 Industries driving the largest proportions of AI transactionsFIGURE 5 Top blocked AI applications and domains by volume of transactionsAI Transaction Trends by VerticalIndustry AI breakdownEnterprise industry verticals show notable differences in their overall adoption ofAI tools as well as the proportion of AI transactions they block. Manufacturing isthe clear leader, driving more than 20% of AI and ML transactions across the ZeroTrust Exchange. Still, the finance and insurance, technology, and services sectorsfollow closely behind. Together, these four industries have pulled ahead of others asthe most aggressive AI adopters.800M600M400M200MManufacturingFinance \& InsuranceTechnologyServicesRetail \& WholesaleHealthcareGovernmentEducation0MMayJulSepNovJanFIGURE 7 AIML transaction trends among the highest\-volume industries,
April 2023January 2024072024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSSecuring AIML transactionsPercent of Blocked AI Transactions by VerticalPaired with the sharp rise in AI transactions,Vertical% of AI transactions blockedindustry sectors are blocking more AItransactions. Here, certain industries divergefrom their overall adoption trends, reflectingdiffering priorities and levels of maturity in termsof securing AI tools. The finance and insurancesector, for instance, blocks the largest proportionof AI transactions: 37\.2% vs. the global averageof 18\.5%. This is likely due in large part to theindustrys strict regulatory and complianceenvironment, combined with the highlysensitive financial and personal user data theseorganizations process.Meanwhile, manufacturing blocks 15\.7% of AItransactions, despite its outsized role in drivingoverall AI transactions. The technology sector,one of the earliest and most eager adopters of AI,has taken something of a middle path, blockingan above\-average 19\.4% of AI transactions as 
it works to scale AI adoption. Surprisingly, theFinance \& InsuranceManufacturingServicesTechnologyHealthcareRetail \& WholesaleOthersEnergy, Oil \& GasGovernmentTransportationEducationhealthcare industry blocks a below\-average 17\.2%Communicationof AI transactions, despite these organizationsprocessing a vast wealth of health data andConstructionpersonally identifiable information (PII). This trendBasic Materials, Chemicalslikely reflects a lagging effort among healthcare\& Miningorganizations to protect sensitive data involvedin AI tools, as security teams play catch\-up to AIinnovation. Overall AI transactions in healthcareremain comparatively low.FIGURE 8
Top industry verticals by percentage 
of AI transactions blockedEntertainmentFood, Beverage \& TobaccoHotels, Restaurants \&LeisureReligious OrganizationsAgriculture \& Forestry37\.1615\.6513\.1719\.3617\.2310\.528\.9314\.246\.757\.902\.984\.294\.122\.921\.333\.663\.166\.060\.18Average across all verticals18\.53082024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSHealthcare and AIRanking as the sixth biggest AIML user, the healthcareVital signs of progress
in AI healthcareindustry blocks 17\.23% of all AIML transactions.While the healthcare industry is typically cautious whenT H ETO PA IA PP SI NH EA LT HCAR EA RE :putting innovations like AI into practice, as seen by its current5% contribution to AIML traffic in the Zscaler cloud, its onlya matter of time before AI has a greater impact on healthcare 
operations, patient care, and medical research and innovation.1Indeed, AI promises to help not only save time, but alsosave lives. Already, AI\-powered technologies are enhancing01ChatGPT06Zineonediagnostics and patient care. By analyzing medical images with02Drift07Securiti03OpenAI08Pypestreamremarkable accuracy, AI helps radiologists detect abnormalities 
more quickly and facilitates faster treatment decisions.2The potential benefits are vast. AI algorithms can use04Writer09Hybridpatient data to personalize treatment plans and accelerate05Intercom10VEEDdrug discovery by efficiently analyzing biological data.Administrative tasks can be automated with generative AI aswell, alleviating burdens on short\-staffed healthcare teams.These advancements underscore AIs capacity to transformhealth provision and healthcare delivery.Key Healthcare Risks: 
Healthcare organizations should acknowledge the potential risks 
and challenges associated with AI, including concerns about data 
privacy and security, especially for personal identifiable information 
(PII), as well as ensuring that AI algorithms and their outputs are 
highly reliable and unbiased when aiding in the administration of 
patient care.1\. Statista, Future Use Cases for AI in Healthcare, September 2023\. 
1\. The Hill, AI already plays a vital role in medical imaging and is effectively regulated, February 23, 2024\.092024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSFinance \& AIIn second place for total AIML usage, the financeindustry blocks 37\.16% of all AIML traffic.Financial institutions bank on AIT H ETO PA IA PP SI NF INANC EA RE :a quarter of AIML traffic in the Zscaler cloud. Whats more,Financial services companies have been leading earlyadopters in the AI era, with the sector accounting for nearly01ChatGPT06Writer02Drift07Hugging Face03OpenAI08Otter Ai04BoldChat 
Enterprise05LivePerson09Securiti10IntercomMcKinsey projects a potential annual revenue of US$200billion to $340 billion from generative AI initiatives in 
banking, largely driven by increased productivity.3 AI quite 
literally represents a wealth of opportunity for banks andfinancial services.While AI\-powered chatbots and virtual assistants arenothing new to finance (Bank of Americas Erica waslaunched in 2018\), generative AI enhancements areelevating these customer service tools to new levels ofpersonalization. Other AI capabilities like predictive modelingand data analysis are poised to deliver massive productivityadvantages to financial operationstransforming frauddetection, risk assessments, and more.Key Finance \& Insurance Risks: 
Integrating AI into financial services and products also raises 
security and regulatory concerns about data privacy, biases, and 
accuracy. The significant 37% of blocked AIML traffic reported 
by ThreatLabz reflects that perspective. Addressing these 
concerns will require astute oversight and planning to maintain 
trust and integrity in banking, financial services, and insurance.3\. McKinsey, Capturing the full value of generative AI in banking, December 5, 2023\.0102024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSGovernment and AIAlthough it falls in the top 10 of AIML usage, theGlobal governments navigate
AI practices and policiesgovernment sector blocks just 6\.75% of AIMLTwo critical AI discussions have emerged in government:transactions.TH ETO PA IA PPLIC AT IONS\*I NG OVE RNMENTARE :one on implementing AI technologies and another onestablishing governance to manage them securely. Theadvantages of AI adoption by government and publicsector entities are substantial, particularly where chatbotsand virtual assistants can give citizens faster access toessential information and services across sectors like publictransportation and education. AI\-driven data analysis01ChatGPT03OpenAIcan help address societal challenges through data\-driven02Drift04Zineone\*AI applications with at least 1M transactionsdecision\-making processes, leading to more efficient policydevelopment and resource allocation.Notable progress is already underway. For example, theUS Department of Justice appointed its inaugural Chief AIOfficer, confirming a commitment to using AI systems.ThreatLabz data indicates that government customers areincreasingly using AIML platforms like ChatGPT and Drift.Key Government Risks: 
Despite these trends, key concerns about AI\-related risks and 
data privacy underscore the continued need for regulatory 
frameworks and governance across federal organizations. In 
general, policymakers worldwide have taken significant steps 
toward AI regulation in the past year, signaling a collective 
effort to drive responsible development and deployment of AI
ML technologies.0112024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSManufacturing 
and AIManufacturing builds on
AI momentumUnsurprisingly, the highest influx of AIML trafficAs the top AIML vertical, the manufacturing vertical(18\.2%) in our research comes from manufacturingblocks 15\.65% of all AIML applications.customers. AI adoption in manufacturing stands as aTO PA PPLIC AT ION SA RE :01ChatGPT06Google Searchcornerstone of Industry 4\.0, a.k.a. the Fourth IndustrialRevolutionan era marked by the convergence ofdigital technologies and industrial processes. From preemptively detecting equipment failures byanalyzing vast amounts of data from machinery andsensors to optimizing supply chain management,02Drift07Zineoneinventory, and logistics operations, AI is proving03OpenAI08Pypestreaminstrumental to manufacturers. Additionally, AI\-drivenrobotics and automation systems can significantly04Writer09Hugging Faceenhance manufacturing efficiency. They can execute05Securiti10Fotortasks at far greater speed and accuracy than humansall while reducing costs and errors.Key Manufacturing AI Risks: 
As for the 16% of blocked traffic from AIML applications by 
manufacturing customers, some manufacturers are approaching 
generative AIML with caution. This may arise from concerns 
regarding the security of manufacturing organizations data as 
well as the need to selectively vet and approve a smaller set of AI 
applications while blocking applications that incur greater risk.0122024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSEducation and AIComing in 11th in overall AIML usage, theeducation vertical blocks 2\.98% of all AIML traffic.TO PA PPLIC AT ION SA RE :Education embraces AI as a
learning toolWhile the education sector is not a top producer of AI traffic,it blocks a comparatively low percentage (2\.98%) of AI andML transactions: approximately 9 million, from a total ofmore than 309 million transactions. Its clear that, despitepopular narratives that education institutions typically blockAI applications like ChatGPT among students, the sectorhas mostly embraced AI applications as learning tools.01ChatGPT05DeepaiNotably, five of the most popular AI apps in education02Character.AI06Drift(ChatGPT, Character.AI, Pixlr, and OpenAI) are explicitly orfrequently focused on creative outputs for writing and image03Pixlr07OpenAIgenerationwhile Forethought, meanwhile, can be used as04Forethoughtan instructional chatbot aid.Adding nuance to this narrative, it may also be that manyeducators block tools like ChatGPT as a matter of classroompolicy, but that educational institutions have lagged behindother sectors in implementing technology solutions like DNSfiltering that allow organizations to block AI and ML tools inmore specific ways.Key Education AI Risks: 
In education, data privacy concerns will likely grow as the 
sector continues to embrace AI tools, specifically surrounding 
protections afforded to students personal data. In all likelihood, 
the education sector will increasingly adopt technological means 
to block selective AI applications, while providing greater data 
protection measures for personal data.0132024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSChatGPT usage trendsChatGPT adoption has soared. Since April 2023, global ChatGPT transactions grew by moreIndustry usage of ChatGPT closely maps to overall adoption patterns of AI tools in general.than 634%, an appreciably faster rate than the overall 595% increase in AI transactions.In this case, manufacturing is the clear industry leader, again followed by finance andFrom these findings and the broad industry perception of OpenAI as the premier AI brand,insurance. Here, the technology sector lags slightly in fourth place, with 10\.7% of ChatGPTits clear that ChatGPT is the favored generative AI tool. In all likelihood, the adoption oftransactions vs. third place and 14\.6% overall. This is likely due in part to the tech sectorsOpenAI products will continue to grow, driven in part by the expected release of newerstatus as a fast innovator, which may mean tech companies are more willing to embrace aChatGPT versions and the companys text\-to\-video generative AI product, Sorabroader variety of generative AI tools.Transactions by Industry VerticalAI Transactions Trends by Verticals
n
o
i
t
c
a
s
n
a
r
Tl
a
t
o
T600M400M200M0MMayJulSepNovJanMonthCommunication
2\.6%
Entertainment2\.7%
Construction2\.8%
Others3\.9%
Healthcare4\.3%Government4\.3%Retail \& Wholesale5\.3%
Transportation5\.3%
Energy, Oil \& Gas4\.7%Technology10\.7%Manufacturing
21\.2%Finance \&
Insurance14\.0%Services13\.4%FIGURE 9 ChatGPT transactions from April 2023 to January 2024FIGURE 10 Industries driving the largest proportions of ChatGPT transactions0142024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024 
KEY GENAI AND ML USAGE TRENDSAI usage by countryAI adoption trends differ markedly worldwide, influenced by regulatory requirements,technological infrastructure, cultural considerations, and other factors. Heres a look at the topcountries driving AI and ML transactions in the Zscaler cloud.As expected, the US produces the lions share of AI transactions. India, meanwhile, hasemerged as a leading generator of AI traffic, driven by the countrys accelerated commitmentto technology innovation. The Indian government also provides a useful example of how fastAI regulation is evolving, with its recent efforts to enact and then drop a plan that 
would require regulatory approval of AI models before they launch.4Transactions by CountryPhilippines
1\.7%
Singapore
1\.9%
Malaysia
1\.9%
Canada
3\.0%
Germany
3\.4%
France
3\.5%
Japan
3\.6%
Australia
4\.1%
United Kingdom
5\.5%United States
40\.9%India
16\.0%FIGURE 11 Countries driving the largest proportions of AI transactions4\. TechCrunch, India reverses AI stance, requires government approval for model launches, March 3, 2024\.0152024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024KEY GENAI AND ML USAGE TRENDSRegion breakdown: EMEAEMEA Country BreakdownTaking a closer look at the Europe, the Middle East, and Africa (EMEA) region, there areclear divergences in rates of AI and ML transactions between countries. While the UKaccounts for only 5\.5% of AI transactions globally, it represents more than 20% of AItraffic in EMEA, making it the clear leader. And while France and Germany unsurprisinglyrank second and third as AI traffic generators in EMEA, rapid tech innovation in theUnited Arab Emirates has solidified the country as a top AI adopter in the region.CountryTransactions% of regionUnited Kingdom76341328920\.47%FranceGermany50418547013\.53%47170068312\.66%United Arab Emirates238557680NetherlandsSpainSwitzerlandItaly222783817198623739129059097975444126\.40%5\.98%5\.30%3\.46%2\.62%FIGURE 12 EMEA countries by total transactionsSyria
0\.0%
Turkey
1\.3%Poland
2\.6%
Switzerland
3\.5%Spain
5\.3%Netherlands
6\.0%United Kingdom
20\.4%France
13\.5%Germany
12\.6%UAE
6\.4%FIGURE 13 EMEA countries by percentage of total AI transactions in regionTransactions (millions) vs. Month8,0006,0004,0002,0000\)
s
n
o
i
l
l
i
m
(s
n
o
i
t
c
a
s
n
a
r
TAprMayJunJulAugSepOctNov Dec JanFIGURE 14 Growth in AI transactions in EMEA over timeMonth0162024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024 
APAC Country BreakdownRegion breakdown: APACDiving deeper into the Asia\-Pacific region (APAC), ThreatLabz research shows clear andnoteworthy trends in AI adoption. Although the region represents far fewer countries,TheatLabz observed nearly 1\.3 billion (135%) more AI transactions in APAC than EMEA.This growth is almost single\-handedly being driven by India, which generates nearly halfof all AI and ML transactions in the APAC region.KEY GENAI AND ML USAGE TRENDSIndonesia
1\.5%
Thailand
1\.5%
China
2\.1%
Hong Kong
4\.0%
Philippines
4\.9%
Malaysia
5\.4%
Singapore
5\.7%
Japan
9\.5%
Australia
10\.0%India
48\.3%FIGURE 16 APAC countries by percentage of total AI transactions in regionTransactions (millions) vs. Month10,0007,5005,0002,5000\)
s
n
o
i
l
l
i
m
(s
n
o
i
t
c
a
s
n
a
r
TAprMayJunJulAugSepOctNov Dec JanFIGURE 17 Growth in AI transactions in APAC over timeMonthCountryIndiaAustraliaJapanSingaporeMalaysiaPhilippinesHong KongChinaTransactions% of region241431949048\.30%50156239510\.01%4764254232848913842680432632437545782021198141045456559\.52%5\.70%5\.36%4\.87%4\.04%2\.09%FIGURE 15 APAC countries by total transactions0172024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024 
REAL\-WORLD AI RISK AND THREAT SCENARIOSEnterprise AI Risk and Real\-World 
Threat ScenariosFor enterprises, AI\-driven risks and threats fall 
into two broad categories: the data protection 
and security risks involved with enabling 
enterprise AI tools; and the risks of a new cyber 
threat landscape driven by generative AI tools 
and automation.Enterprise AI risk1Protecting intellectual property and
non\-public informationGenerative AI tools can lead to inadvertent leakage of sensitive and confidential data.In fact, sensitive data disclosure is number six on the Open Worldwide Application 
Security Project (OWASP) Top Ten for AI Applications.5 The past year has seen numerous 
instances of accidental data leakages or breaches of AI training data, including from cloudmisconfigurations, from some of the largest AI tool providerssome exposing terabytesof customers private data.A related risk is the threat of model inversion, whereby attackers use the outputs of an 
LLM paired with knowledge about its model structure to make inferences about, andeventually extract, its training data. Of course, there is also the risk that AI companiesthemselves will be breached. There have been cases where the credentials of AI companyemployees have led directly to data leaks.Meanwhile, there is the chance that adversaries will launch secondary malware attacks, 
using information stealers like Redline Stealer or LummaC2, to steal employee logincredentials and gain access to their AI accounts. In fact, it was recently disclosed thatroughly 225,000 ChatGPT user credentials are listed for sale on the dark web, stemming 
from this type of attack.7 While privacy and data security remain top priorities at AI tool 
providers, these risks remain in play, and they extend equally to smaller AI companies, SaaSproviders that have enabled AI functionality, and the like.Finally, there is the risks stemming from enterprise AI users themselves. There are 
numerous ways a user may unknowingly expose valuable intellectual property or non\-publicinformation into the data sets used to train LLMs. For instance, a developer requesting 
optimization of source code or a sales team member seeking sales trends based oninternal data could unintentionally disclose protected information outside the organization.It is crucial for enterprises to be aware of this risk and implement robust data protectionmeasures, including data loss prevention (DLP), to prevent such leaks.ACC ES SCO NT RO LA N DS EGMEN TAT IO NR IS KAccess controls, such as role\-based access control (RBAC), can be misconfigured orabused for AI applications. This can lead to circumstances where, for instance, an AI 
chatbot generates the same responses for a CEO as for any other enterprise user,In one example, researchers exposed thousands of GitHub secrets from GitHubs Copilotwhich poses particular risks when chatbots are trained on historical data from thatAI by exploiting a vulnerability called prompt injectionusing AI queries designed tousers inputs. This could be used to infer information about the queries that executivesmanipulate the AI to divulge training datawhich incidentally is the number one OWASP 
Top 10 risk.6have sent using AI chatbots. Here, enterprises should take care to appropriatelyconfigure AI application access controls, enabling both data security and accesssegmentation based on user permissions and roles.5\. OWASP, OWASP Top 10 For LLM Applications, Version 1\.1, October 16, 2023\. 
1\. The Hacker News, Three Tips to Protect Your Secrets from AI Accidents, February 26, 2024\. 
1\. The Hacker News, Over 225,000 Compromised ChatGPT Credentials Up for Sale on Dark Web Markets, March 5, 2024\.0182024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024REAL\-WORLD AI RISK AND THREAT SCENARIOS2Data privacy and security risks of
AI applicationsAs the number of AI applications grows dramatically, enterprises mustA ID ECISIO NP OINT: WH E NTOB LO C KA I, WH E NTOA L LOW AI,AN DH OW TOM ITI GAT ES HAD OW A IR IS Kconsider that all AI applications are not equal when it comes to data privacyEnterprises are at a crossroads: enabling AI applications to transform productivity vs. blockingand security. Terms and conditions can vary greatly from one AIMLthem to protect sensitive data. To take an informed and secure approach to this transition,application to another. Enterprises must consider whether their queries willenterprises should know the answers to five critical questions:be used to further train language models, mined for advertising, or sold tothird parties. Additionally, the security practices of these applications and 
the overall security posture of the companies behind them can vary. To 
ensure data privacy and security, enterprises need to assess and assign 
risk scores to the multitude of AIML applications they use, taking into 
account factors like data protection and the companys security measures.3Data quality concerns: garbage in,
garbage out01Do we have deep visibility into employee AI app usage? Enterprises must have totalvisibility into the AIML tools in use as well as corporate traffic to those tools. Just thesame as Shadow IT, Shadow AI tools will proliferate in the enterprise.02Can we create granular access controls to AI apps? Enterprises should be able toenable granular access and microsegmentation for specified, approved AI tools at thedepartment, team, and user levels. Conversely, enterprises should use URL filtering toblock access to unsecure unwanted AI applications.Finally, the quality and scale of data used to train AI applications musttools in everyday use. Enterprises should know the data security measures each provides.always be scrutinized, as it is tied directly to the value and trustworthiness 
of AI outputs. Although large AI vendors like OpenAI train their tools onOn a spectrum, certain AI tools can enable a private, secure data server in the enterprise 
environmenta best practicewhile others will retain all user data, use input data towidely available resources like the public internet, vendors with AI productsfurther train the LLM, or even sell user data to third parties.03What data security measures do specific AI apps enable? There are thousands of AIin specialized or verticalized industries, including cybersecurity, must traintheir AI models on highly specific, large\-scale, often private data sets todrive reliable AI outcomes. Thus, enterprises need to carefully consider thequestion of data quality when evaluating any AI solution, as garbage inreally does translate to garbage out.More broadly, enterprises should be aware of the risks of data 
poisoningwhen training data is contaminated, impacting the reliability 
or trustworthiness of AI outputs.8 Regardless of the AI tool, enterprises 
should establish a strong security foundation to prepare for sucheventualities while continually evaluating whether AI training data andGenAI outputs meet their quality standards.04Is DLP enabled to protect key data from being leaked? Enterprises should enable DLPto prevent sensitive information, like proprietary code or financial, legal, customer, andpersonal data, from leaving the enterpriseor even being entered into AI chatbotsparticularly where AI apps have looser data security controls.05Do we have appropriate logging of AI prompts and queries? Finally, enterprises should 
collect detailed logs that provide visibility into how their teams are using AI toolsincluding the prompts and data being used in tools like ChatGPT. 8\. SC Magazine, Concerns over AI data quality gives new meaning to the phrase: garbage in, garbage out, February 2, 2024\.0192024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024REAL\-WORLD AI RISK AND THREAT SCENARIOSAI\-driven threat scenariosEnterprises face a continuous barrage of cyberthreats, and today, that includes attacksAI impersonation: deepfakes,
misinformation, and moredriven by AI. The possibilities of AI\-assisted threats are essentially limitless: attackers areThe era of AI\-generated videos, live avatars, and voice impersonations that are near\-using AI to generate sophisticated phishing and social engineering campaigns, create highlyindistinguishable from reality has arrived. In 2023, Zscaler successfully thwarted an AIevasive malware and ransomware, identify and exploit weak entry points in the enterprisevishing and smishing scenario where threat actors impersonated the voice of Zscaler CEOattack surface, and overall increase the speed, scale, and diversity of attacks. This putsJay Chaudhry in WhatsApp messages, which attempted to deceive an employee intoenterprises and security leaders in a double bind: they must expertly navigate the fast\-purchasing gift cards and divulging more information. ThreatLabz then identified this asevolving AI landscape to reap its revolutionary potential, yet they must also face down thepart of a widespread campaign targeting other tech companies.unprecedented challenge of defending and mitigating risk against AI\-powered attacks.Although these attacks can often be stopped in simple ways, such as confirming thevalidity of a message directly with colleagues over a separate trusted channel, they can bevery convincing. In a high\-profile example, attackers using AI deepfakes of a company CFOconvinced an employee at a Hong Kong\-based multinational firm to wire the equivalent ofUS$25 million to an outside account. While the employee suspected phishing, their fearswere calmed after joining a multi\-person video conference that included the company CFO,other staff, and outsiders. The calls attendees were all AI fakes.AI threats will come in many flavors. With the notable trend toward vishing (voice vishing)in 2023, one key trend will be the use of AI to carry out identity\-driven social engineeringattacks seeking administrative user credentials. Recent ransomware attacks by ScatteredSpider, an affiliate group of BlackCatALPHV ransomware, showed how effective voice 
communications can be in gaining a foothold in target environments to subsequently deployfurther ransomware attacks. AI\-generated attacks will pose even greater challenges indetecting and defending against these attacks.Enterprises must approach security in 2024 with the expectation that employees will betargeted by AI deepfake and phishing campaigns. Employee training will be an essentialpiece of the cybersecurity puzzlemaking the immediate reporting of any suspiciousactivity the norm. As part of this arms race, enterprises should also evaluate the rapidlyevolving set of AI\-powered cyber defenses that can identify AI\-generated phishing attacksas a key part of their arsenal.NOTE:For demonstration purposes, this example shows lightly abbreviated prompts and includes a ChatGPT coderesponse for one query before showing the final rendered phishing page.0202024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024REAL\-WORLD AI RISK AND THREAT SCENARIOSAI\-generated phishing campaignsIn a similar fashion, threat actors are using generative AI to launch sophisticated, highly convincing phishingNext, ThreatLabz provided a short series of prompts to improve theand social engineering attacks at greater speed and scale. At the simplest level, AI chatbots like ChatGPT allowpage before rendering the final Microsoft phishing login page. Thesecybercriminals to instantly craft phishing emails in perfect prose, with persuasive language that can mimic anyincluded asking ChatGPT to make the page look like a Microsoft login,speaker, regardless of the native language of the attacker. That is, typical tells that can give away standardadjusting the logo size, and adding and removing UI elements beforephishing emails (e.g incorrect grammar, awkward syntax, or out\-of\-place language) will largely cease to exist.submitting the final query to generate the final code output.From query to crime: creating a phishing login page 
using ChatGPTNot only that: LLMs have also made it significantly easier for cybercriminals, even with relatively little codingexperience, to carry out multiple stages of a sophisticated phishing attack. For instance, in just a few promptsusing a generative AI chatbot like ChatGPT, its almost trivial to create fake phishing login pages that mimicpopular enterprise applications to steal employee login credentials. The following example from ThreatLabzshows how simple it is to create a convincing fake Microsoft login page with just a few conversational prompts.User prompt: create an HTML login page
ChatGPT: Sure, heres a basic example of an HTML login page:User prompt: add a page background that is similar to the microsoft 
login pageChatGPT:I N7QU ERIES,TH EF INA LR ESU LT:THI SWAST H EF IR STR ESU LT:FIGURE 19 Screenshot of the final rendered Microsoft phishing login 
page, using the ChatGPT code responseFIGURE 18 Screenshot of a rendered login page using the 
ChatGPT code response0212024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024REAL\-WORLD AI RISK AND THREAT SCENARIOSDark chatbots: uncovering WormGPT 
and FraudGPT on the dark webPopular AI chatbots like ChatGPT have security controls in place thatin most casesprevent users fromgenerating malicious code. Less constrained versions of generative AI, so\-called dark chatbots, have nosuch guardrails. As a result, sales of the most popular dark chatbots, including WormGPT and FraudGPT,have proliferated on the dark web. While many of these tools are billed as aids to security researchers,they are predominantly used by threat actors to generate malicious code like malware with AI.To uncover how easy it is to acquire these tools, ThreatLabz delved into dark web listings. ThreatLabzfound how, rather appropriately, the creators of these tools leverage generative AI chatbots to maketheir purchase surprisingly simple: with a single prompt on the WormGPT purchasing page, for instance,users are prompted to buy a trial version by sending payment to a bitcoin wallet. Note that the creatorsspecifically state that, in theory, WormGPT is geared toward security research and defense.However, with one download, anyone can get access to a fully featured generative AI tool that can beused to create, test, or optimize any variety of malicious code, including malware and ransomware, withno security guardrails. While researchers have shown that popular AI tools like ChatGPT can be jailbrokenfor malicious purposes, their defenses against these actions have grown continuously. As a result, sales oftools like WormGPT and FraudGPT will only continue to grow, as will best practice examples of how toeffectively create and optimize malware among threat actor communities on the dark web.FIGURE 20 Screenshot of the dark chatbot WormGPT0222024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024REAL\-WORLD AI RISK AND THREAT SCENARIOSAI\-driven malware and ransomware across the attack chainAI is helping threat actors and state\-sponsored adversaries launch ransomware attacks witheven if enterprises maintain a strong security posture, downstream vulnerabilities can oftengreater ease and sophistication across multiple stages of the attack chain. Before the adventpose the greatest risks. As attackers continuously experiment with generative AI, this willof AI, when launching an attack, threat actors had to spend considerable time identifying anform an iterative feedback loop for improvement that results in more sophisticated, targetedenterprises attack surface and internet\-facing vulnerabilities in services and applications. Now,attacks that are even more challenging to mitigate.using generative AI, that information is instantly queryable with a prompt such as: Create atable showing the known vulnerabilities for all firewalls and VPNs in this organization. Next,attackers can use the LLM to generate or optimize code exploits for those vulnerabilities withcustomized payloads for the target environment.The following diagram illustrates some of the key ways attackers can leverage generativeAI across the ransomware attack chainfrom automating reconnaissance and codeexploitation for specific vulnerabilities, to generating polymorphic malware and ransomware.By automating critical portions of the attack chain, threat actors are able to generate faster,Beyond that, generative AI can also be used to identify weaknesses among enterprise supplymore sophisticated, and more targeted attacks against enterprises.chain partners while highlighting optimal routes to connect to the core enterprise network;AI\-driven ransomware attacksReconnaissanceInitial compromiseLateral movementData loss \& malware deliveryGain initial entryEstablish 
footholdDeliver 
malwareInstall
malwareSteal credentials \&
compromise additional systemsDomain controllerSteal dataInstall ransomware 
\& demand paymentGen AI discovery of attack 
surface: vulnerabilities for 
exposed assets (e.g. VPNs)AI\-generated polymorphic malwareAI\-driven phishing and vishing attacksEscalate privilege
\& Identify crown\-jewelsSteal data and deploy
AI\-powered exfiltration
modules (likely emergent)FIGURE 21 How threat actors can leverage AI across the ransomware attack chain0232024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024 
REAL\-WORLD AI RISK AND THREAT SCENARIOSUsing ChatGPT to create vulnerability 
exploits for Apache HTTPS Server 
and Log4j2Diving deeper, the following case study shows how threat actors can leverage these capabilities in practice.ThreatLabz used ChatGPT to quickly generate code exploits for two noteworthy CVEs: the Apache HTTPserver path traversal vulnerability (CVE\-2021\-41773\) and the Apache Log4j2 remote code executionAI worm attacks and viral AI jailbreakingGenerative AI tools even give threat actors entirely new avenues ofattack, including attacks focused on extracting data from generativeAI tools themselves. For instance, researchers have demonstrated the 
viability of AI worm attacks.9,10 These self\-propagating malware 
attacks can spread organically through an AI ecosystem (in particularthird\-party AI tools and assistants that leverage popular generative AItools) and extract sensitive user data.vulnerability (CVE\-2021\-44228\). Our researchers were able to generate working code with ChatGPT usingIn one case, researchers targeted generative AI email assistants thatonly conversational prompts that require low levels of coding knowledge, such as, Can you give me a POC inleverage Gemini Pro, ChatGPT 4\.0, and the Microsoft\-developed LLMpython for CVE\-2021\-41773\.As a note, for demonstration purposes, ThreatLabz referred to known\-exploited CVEs from CISA that wereadded before December of 2021\. In general, the free version of ChatGPT limits information related to CVEsthat were documented before January, 2022\.FIGURE 22 Using ChatGPT to generate a code exploit for CVE\-2021\-44228LLaMa. The researchers found that AI worm attacks can send usersspam emails with zero\-click malwarewhich doesnt require users tofollow a malicious linkto exfiltrate their personal data. While suchattacks have been limited to research environments for the time being,the researchers validated their effectiveness against numerous AImodels, and enterprises can expect these kinds of attacks to propagateamong cyberthreat groups eventually.Elsewhere, researchers have shown how adversarial images and promptscan be used to spread virally and jailbreak multimodal LLMs (MLLMs), 
which are GenAI tools that leverage many LLM agents. 11MLLMs are 
becoming popular due to their potential to improve the performanceof a generative AI tool. In one study, a single malicious image shownto one large language\-and\-vision assistant (LLaVA) agent was able tospread exponentially to its connected agents, jailbreaking up to onemillion LLaVA agents in short order. These threats pose significantrisks to this particular variety of LLM, so enterprises should exercisecaution in adopting them before robust, best practice defenses areclearly established.9\. Wired, Here Come the AI Worms, March 1, 2024\. 
1\. ComPromptMized, Unleashing Zero\-click Worms that Target GenAI\-Powered Applications, 
accessed March 12, 2024\.
1\. arXiv, Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents 
Exponentially Fast, February 13, 2024\.0242024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024REAL\-WORLD AI RISK AND THREAT SCENARIOSAI and US electionsThe impact of AI on US elections is a growing concern. Theemergence of deefakes, for instance, makes it significantly easier forbad actors to spread misinformation and influence the voting public.In the current election cycle, we have already witnessed AI\-generatedrobocalls impersonating incumbent President Joe Biden to discouragevoter turnout in an early primary. Alarming incidents like this are likelyjust the beginning for AI\-driven disinformation strategies.Its important to note that the use of AI in these schemes may not belimited to domestic actors; state\-sponsored entities could also exploitAI to create confusion and undermine trust in the electoral process. Inreports to the Senate Intelligence Committee, US intelligence agencieshave warned that Russia and China will likely leverage AI as part ofattempts to influence US elections.Even outside of politics, the social media circulation of deepfakeimages featuring celebrities like Taylor Swift highlights how easilymanipulated content can spread before it can be effectively moderated.AI companies are taking steps to help mitigate this risk; GoogleGemini, for instance, has enacted guardrails that prevent users from 
asking about upcoming elections in any country. As AI continues toadvance, steps must be taken to address the potential risks it posesto the integrity of US elections and to ensure the publics trust in thedemocratic process.0252024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024All Eyes on AI RegulationGiven its substantial economic impact potential, governments 
worldwide are actively working to regulate AI and foster its safe 
usage. To date, there have been at least 1,600 AI policy initiatives 
from 69 countries and the EU spanning AI regulations, national 
strategies, grants and investments, and more.14,15Broadly speaking, these efforts seek to understand AI impacts, spur innovation, and shape its responsible developmentthrough policy. AI regulations will continue to develop and evolve rapidly, but a few recent regulatory changes canprovide a useful snapshot for enterprises seeking to understand these trends.United StatesIn the US, the focus has been on the White House Executive Order on the Safe, Secure, and Trustworthy Development 
and Use of Artificial Intelligence,16 which compels developers of the largest AI systems to report safety test results to the 
Department of Commerce as well as disclose when large new compute resources are used to train AI models. It furtherrequired nine federal agencies to complete risk assessments on the impact of AI on critical infrastructure. The WhiteHouse is also focused on AI innovation: as part of the EO, the US government established the National ArtificialIntelligence Research Resource (NAIRR) pilot program to connect US researchers to computational power, data, and 
other tools to develop AI.17It remains to be seen whether the US government will seek more binding regulations around AI. As of now, at least 15leading AI companies and nearly 30 healthcare companies have signed on to voluntary White House commitments to 
safeguard AI.18 Meanwhile, the FTC has banned the use of AI to impersonate a governmental agency or business, with plans 
to expand the rule to include protections for private individuals and agencies.19 The White House is also reportedly exploring 
the possibility of requiring watermarks for AI\-generated conten14\. OECD, Policies, data and analysis for trustworthy artificial intelligence, accessed 
March 12, 2024\. 
1\. Deloitte, The AI regulations that arent being talked about, accessed March 12, 2024\.
1\. White House, Executive Order on the Safe, Secure, and Trustworthy Development 
and Use of Artificial Intelligence, October 30, 2023\.
17\.NAIRR Pilot, The National Artificial Intelligence Research Resource (NAIRR) Pilot, 
accessed March 12, 2024\. 
1\. Reuters, Healthcare providers to join US plan to manage AI risks \- White House, 
December 14, 2023\.
1\. Pennsylvania Office of Attorney General, FTC Bans Use of A.I. to Impersonate 
Government Agencies and Businesses, February 26, 2024\.0262024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024ALL EYES ON AI REGULATIONSEuropean UnionThe European Parliament has recently approved the AI Act, which will establish the worldsfirst comprehensive AI legislation, with a stringent set of laws and guidelines for differenttypes of AI applications, categorized by risk across many industries. Expected to take effectin 2026, the laws will require, for instance, general\-purpose AI tools such as ChatGPT tocomply with transparency requirements, such as that content was generated by AI, thattraining models were designed to prevent generating illegal content, and that companiesprovide summaries of copyrighted materials used for training.The regulations will apply stricter policies to high risk AI applications, such as those usedin consumer products, including toys, aviation, medical devices, and vehicles, as well asAI that impacts particular areas such as critical infrastructure, employment, legal affairs,immigration, and more. Meanwhile, the EU will outright ban AI applications deemedunacceptably risky, including those that use sensitive biometric information, seek tomanipulate human behavior to circumvent free will, use emotional recognition for hiring and 
education, or scrape untargeted facial images from the internet or CCTV.20Many countries are also prioritizing AI investments. Singapore, for instance, has announced 
a $740 million AI investment plan as part of the countrys National AI Strategy 2\.0\.21 This 
plan will work to drive AI innovation, enabling access to advanced chips required for AI whileensuring that enterprises are poised to capitalize on the AI revolution with Singapore\-based 
AI centers of excellence.20\. European Parliament, EU AI Act: first regulation on artificial intelligence, December 19, 2023\. 
1\. CNBC, Singapores AI ambitions get a boost with $740 million investment plan, February 19, 2024\.0272024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024AI Threat PredictionsAI\-generated misinformation and cyber 
attacks represent \#2 and \#5 of the top 10 
global risks in 2024, per the World Economic 
Global Risk Report.22Although targeted intervention has stopped some of these attacks, enterprises should bracefor the persistence of state\-backed AI initiatives. The scope encompasses the deploymentof popular AI tools, the creation of proprietary LLMs, and the emergence of unconstrainedChatGPT\-inspired variants, such as the aptly\-named FraudGPT or WormGPT. The evolvinglandscape paints a challenging picture in which state\-sponsored actors continue to leverageAI in novel ways to create complex new cyberthreats.As the field of AI continues to rapidly evolve, including in the area of AI\-generated videosand images, these risks will only growas will our ability to harness AI to mitigate them.Looking to the rest of 2024 and beyond, these are the top AI risk and threat predictionswe see on the horizon.1Nation\-states AI dilemma: driving 
AI threats while blocking AI accessState\-sponsored threat groups are poised to develop a complex relationship with AI,using it to generate more sophisticated threats while also striving to block access toanti\-regime content.Use of AI tools by state\-sponsored threat groups is not a new phenomenon, but itsanticipated trajectory points to significant growth in both scale and sophistication.Reports from Microsoft and OpenAI validate this concern, revealing that threat actorgroups supported by nations like Russia, China, North Korea, and Iran have actively delvedinto and exploited ChatGPT functionality. This extends across various use cases, includingspear phishing, code generation and review, and translation.22\. World Economic Forum, Global Risks Report 2024: The risks are growing but so is our capacity to respond, 
January 10, 2024\. 
1\. ZDNet, Cybercriminals are using Metas Llama 2 AI, February 21, 2024\.2Dark chatbots and AI\-driven attacks: the 
scourge of AI for bad will growAI\-driven attacks are likely to surge throughout the year as the dark web serves asa breeding ground for malicious chatbots like WormGPT and FraudGPT to amplifycybercriminal activities.These insidious tools will become instrumental in executing enhanced social engineering,phishing scams, and various other threats. The dark web has seen an upswing indiscussions among cybercriminals delving into the illicit deployment of ChatGPT andother generative AI tools for a spectrum of cyberattacks. More than 212 malicious LLMapplications have been identified, representing only a fraction of what is availableand thatnumber is expected to steadily grow.Mirroring developers who use generative AI for efficiency gains, threat actors employ thesetools to uncover and exploit vulnerabilities, fabricate convincing phishing schemes, executevishing and smishing campaigns, and automate attacks with greater speed, sophistication, 
and scale. For example, the threat actor group Scattered Spider recently used Metas LLaMa2 LLM to exploit Microsoft PowerShell functionality, enabling unauthorized download of 
user credentials.23 The trajectory of these advancements indicates that cyberthreats will 
begin to evolve more quickly than ever, taking on new forms that are more difficult torecognize or defend against with traditionalsecurity measures.0282024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024AI THREAT PREDICTIONS3Fighting AI with AI: security roadmaps and 
spend will include AI\-driven defensesEnterprises will increasingly adopt AI technologies to combat AI\-driven cyberattacks, includinga focus on using deep learning and AIML models to detect malware and ransomware hiddenin encrypted traffic. Traditional detection methods will continue to struggle with new AI\-drivenzero\-day attacks and polymorphic ransomware (which can evolve its code to evade detection),so AI\-based indicators will be crucial in identifying potential threats. AI will also play a vitalrole in swiftly identifying and stopping convincing AI\-generated phishing and other socialengineering attacks.Enterprises will increasingly incorporate AI in their cybersecurity strategies. AI will be seenas a critical means to gain visibility into cyber risk as well as create actionable, quantifiableplaybooks to prioritize and remediate security vulnerabilities. Translating noise into practicalsignals has long been a top challenge for CISOs, because correlating risk and threat informationacross dozens of tools can take a month or more. As such, in 2024, enterprises will lookeagerly to generative AI as a way to bring order to chaos, defray cyber risk, and drive leaner,more efficient security organizations.4Data poisoning in AI supply chains: the risk 
of garbage AI data will growData poisoning will become a top concern as AI supply chain attacks gain momentum. AIcompanies as well as their training models and downstream suppliers will be increasinglytargeted by malicious actors.The OWASP Top 10 for LLM Applications highlights training data poisoning and supply chainattacks as significant risks, running the risk of compromising the security, reliability, andperformance of AI applications. Simultaneously, vulnerabilities in AI application supply chains
including technology partners, third\-party data sets, and AI tool plugins or APIsare ripe forexploitation.Enterprises reliant on AI tools will face heightened scrutiny as they assume these tools aresecure and produce accurate results. Greater vigilance in ensuring the quality, integrity, andscalability of training data sets will be essential, particularly in the realm of AI cybersecurity.0292024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024AI THREAT PREDICTIONS5To leash or unleash: enterprises will weigh 
productivity vs. security in their use of 
AI toolsBy now, many enterprises are past the early phases of AI tool adoption and integration, andmany will have carefully considered their AI security policies. Even so, this is a fluid situation formost companies, and questions around which AI tools they will allow, which they will block,and how they will secure their data remain open.As the number of AI tools continues to skyrocket, enterprises will need to pay close attentionto the security concerns of eachat a minimum, seeking deep insight into their employees AIusage, with an ability to enable granular access controls by department, team, and even at theuser level. Enterprises may also seek more granular security controls over AI apps themselves,such as by enforcing data loss prevention policies in AI appspreventing sensitive data fromleakingor preventing user actions such as copy and paste.6AI\-driven deception and distortion: viral 
deepfakes will fuel election interference and 
disinformation campaignsEmerging technologies like deepfakes pose significant threats, including election interferenceand the spread of misinformation. AI has already been implicated in misleading tacticsduring US elections, such as generating robocalls impersonating candidates to discouragevoter turnout. These instances, while alarming, likely represent the tip of the AI\-drivendisinformation iceberg.Furthermore, the use of AI in such schemes may not be limited to domestic actors. State\-sponsored entities could also exploit these tactics to sow confusion and undermine trust in 
the electoral process. In a notable case, attackers utilized AI\-generated deepfakes to trick anemployee into transferring $25 million, demonstrating the real\-world impact of this technology.Similarly, illicit deepfake images of celebrities like Taylor Swift have gone viral on social media,calling attention to how easily manipulated content can spread before content moderationmeasures can catch up.0302024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024Case Study: Securely Enable 
ChatGPT in the EnterpriseBest practices for AI integration and enterprise 
security policy.C AS EST U DY5 steps to integrate and secure generative 
AI toolsBy now, enterprises have had plenty of exposure to AI tools. But as the number of AIEnterprises seeking to securely adopt AI applications should take a measured approach.applications continues to grow dramatically and adoption continues apace, enterprises canBroadly speaking, they can first block all AI applications to eliminate the risk of dataadopt certain best practices to keep their data, employees, and customers safe. Overall,leakage, and then take thoughtful steps to adopt specific, vetted AI applications with tightenterprises must proactively and continually adapt their AI usage and security strategies tosecurity controls and access control measures to maintain complete control over enterprisestay ahead of evolving risks while ushering in the transformative potential of AI.data. For simplicitys sake, the following journey focuses on OpenAIs LLM ChatGPT.Step 1:Block all AI and ML domains and applicationsTo eliminate known and unknown risks associated with the thousands of AI applicationsavailable, enterprises can take a proactive zero trust approach, blocking all AI and MLdomains and applications at the global enterprise level. This way, they can focus on 
adopting a minimum set of transformative AI applications while closely controlling theirrisks.Step 2:Selectively vet and approve generative AI applicationsNext, the organization should identify a set of generative AI applications that exceedhigh standards for certain criteria, such as the ability to create robust data protection,security, and contractual measures to protect enterprise and customer data, as well as thetransformative potential of the applications themselves. For many enterprises, ChatGPT willbe one of these applications.Step 3:Create a private ChatGPT server instance in the
corporateDC environmentTo ensure complete control over their data, organizations should host ChatGPT in adedicated, secure tenant (such as a private Microsoft Azure AI server) hosted fully withinthe organization. Then, through security controls and contractual obligations, enterprises 
should ensure that neither Microsoft and OpenAI (in this example) has access to enterprise0312024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024ZSCALERS AI JOURNEYor customer data, nor will enterprise user queries be used to train ChatGPT at large. This ensuresthe organization retains control over its training data, allowing for highly relevant, accurate answersAI best practicesfor enterprise users while minimizing the risk of data poisoning from a public data lake.In general, enterprises can adopt a few key best practices when it comes toStep 4:Move the LLM behind single sign\-on (SSO) with strong multifactor
authentication (MFA)Next, the organization should move ChatGPT behind a zero trust cloud proxy architecture, such asthe Zscaler Zero Trust Exchange, to enforce zero trust security controls over access to ChatGPT.This might also include moving ChatGPT behind an identity provider (IdP) with SSO authenticationand strong MFA that includes biometric authentication. This will enable secure and fast user loginto ChatGPT while also allowing the enterprise to configure granular access controls at the user,team, and department levels. This also ensures a separation of concerns between user queries atthose same user, team, and departmental levels.Placing ChatGPT behind a cloud proxy like the Zero Trust Exchange further enables the organizationto inspect all TLSSSL traffic between users and ChatGPT to detect cyberthreats and data leakagewhile applying seven distinct layers of zero trust security.Step 5:Enforce the Zscaler DLP engine to prevent data leakagesintegrating AI tools into the business.Continually assess and mitigate the risks that come withAI\-powered tools to protect intellectual property, personal data, and
customer information.Ensure that the use of AI tools complies with relevant laws and ethical standards,including data protection regulations and privacy laws.Establish clear accountability for AI tool development and deployment, includingdefined roles and responsibilities for overseeing AI projects.Maintain transparency when using AI toolsjustify their use and communicatetheir purpose clearly to stakeholders.AI policy guidelinesFinally, the organization should enforce a DLP engine for the ChatGPT instance to prevent accidentalEnterprises should go behind these best practices and establish a clear policyleakage of critical information, including proprietary data and code, customer data, personal data, 
financial and legal data, and more. This ensures that any highly sensitive data will never leave theframework that governs enterprise\-wide acceptable use, integration and product 
development, security and data policies, and employee best practices whenproduction environment.using AI tools. The following best practices can form a useful starting point forBy following this journey, enterprise users can reap the full benefits of a generative AI tool likeestablishing clear AI policies.ChatGPT while eliminating the most critical data risks of adopting an AI application.Do not provide AI models with personally identifiable information (PII) or anynon\-public, proprietary, or confidential information.AI cannot replace a human being, and it should not be used to make decisionswithout appropriate human intervention.AI\-generated content should not be used without human review and approval,especially when the content represents your organization.Development and integration of AI tools should follow a Secure Product LifecycleFramework to guarantee the highest level of security.Perform thorough product due diligence before implementing AI solutions,making sure to evaluate their security and ethical implications.0322024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024How Zscaler Delivers AI \+ Zero Trust 
and Secures Generative AIThe transformative power of AI in cybersecurity lies in its ability to be 
harnessed to combat the evolving landscape of AI\-driven threats. At 
Zscaler, were leveraging AI to help enterprises stop attacks across all 
stages of the attack chain as well as easily diagnose and mitigate risk.The key to AI\-driven cybersecurity: 
high\-quality data at scaleEnterprises generate a vast wealth of log data that can contain high\-fidelity signals that may indicate likely avenues for a 
breach. However, signal\-to\-noise challenges have historically made it a challenge to isolate these signals quickly. Usinggenerative AI, Zscaler can leverage this data to effectively enhance triage and protection measures by understandingthe vulnerabilities and weaknesses attackers are likely to exploit. This not only allows Zscaler to predict breaches beforethey happen, but also gives executives a holistic way to visualize and quantify cyber maturity and risk while prioritizingcybersecurity remediation steps with Zscaler Risk360\.Generative AI capabilities not only extend to meta\-analysis of enterprise cyber riskthey are also directly inserted intocybersecurity products to better detect and disrupt advanced threats across the attack chain. Directly integrated into theworlds largest security cloud, Zscaler LLMs and AI models take advantage of a data lake that sees more than 390 billiondaily transactions, with more than 9 million blocked threats and 300 trillion signals. Far from garbage in, garbage out,this is large\-scale, high\-fidelity data and threat intelligence in, finely\-tuned, hyper\-aware AI cybersecurity out. All of 
this translates to more powerful, more effective cybersecurity outcomes for IT and security practitioners.0332024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024HOW ZSCALER DELIVERS AI \+ ZERO TRUST AND SECURES GENERATIVE AILeveraging AI across the 
attack chainA I \- P OWE RE DP HISHIN GA N DC 2P RE VE NTIO NZscaler AI models detect known and patient\-zero phishing sites to prevent credential theftand browser exploitation, as well as analyze traffic patterns, behavior, and malware todetect never\-before\-seen command\-and\-control (C2\) infrastructure in real time. TheseWeve discussed numerous ways threat actors are using AI to launch sophisticatedmodels draw on a combination of threat intelligence, ThreatLabz research, and dynamicthreats at greater speed and scale. Zscaler deploys AI capabilities across the Zero Trustbrowser isolation to detect suspicious sites. As a result, enterprises are even more efficientExchange platform and cyber product suite to identify and stop both AI\-driven andand effective in detecting new phishing attacks, including AI\-generated attacks, and C2conventional attacks at each stage of the attack chain.domains.Stage 1:Attack surface discoveryF ILE \- BAS E DA ISA NDB OXD EFENS EThe first stage of a cyberattack typically involves threat actors probing the internet\-The AI\-powered inline Zscaler Sandbox instantly detects malicious files while keepingconnected enterprise attack surface to identify exploitable weaknesses. Often, thisemployees productive. Traditional sandbox technologies make users wait while files areincludes things like VPN or firewall vulnerabilities and misconfigurations or unpatchedanalyzed, or else assume patient\-zero risk when files are allowed on first pass. Our AIservers. Generative AI has made this once\-arduous task significantly easier for attackers,Instant Verdict technology instantly identifies, quarantines, and prevents high\-confidencewho can simply query a list of known vulnerabilities associated with these assets.malicious filesincluding zero\-day threatswhile removing the need to wait for analysisLeveraging AI\-driven insights in Zscaler Risk360, enterprises can instantly see thesediscoverable (and thus risky) applications and assetstheir internet\-connected attacksurfaceand hide them from the public internet behind the Zero Trust Exchange.This instantly and dramatically reduces the enterprise attack surface while preventing 
attackers from ever discovering weak entry points.Stage 2:Risk of compromiseon these files. This includes threats that are delivered over encrypted channels (TLS andHTTPs) and other file transfer protocols. Meanwhile, benign files are delivered safely andinstantly.A ITOB LO C KWE BT HRE AT SAI\-powered Zscaler Browser Isolation blocks zero\-day threats while ensuring employeescan access the right sites to do their jobs. In practice, enterprise URL filtering often requiresmore granular controls than allowblock; blocked sites are often safe and required forDuring the compromise stage, attackers work to exploit vulnerabilities to gainwork, resulting in needless help desk tickets. Our AI Smart Isolation can identify when a siteunauthorized access to enterprise systems or applications. Zscaler AI innovations helpmay be risky and open it in isolation for the usersafely streaming the site as pixels in areduce the risk of compromise, breaking up sophisticated attacks while prioritizingsecure, containerized environment. This effectively stops web\-based threats like malware,productivity.ransomware, phishing, and drive\-by downloads, creating a strong web security posturewithout requiring enterprises to overblock sites as a default.0342024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024HOW ZSCALER DELIVERS AI \+ ZERO TRUST AND SECURES GENERATIVE AIStage 3:Lateral movementOnce attackers have a foothold inside anorganization, they will try to move laterallyto access sensitive data and applications.And for many organizations, user access isvastly overprovisioned to dozens of criticalapplicationsmeaning that their internalattack surface is substantial.Zscaler AI capabilities reduce the potentialblast radius of attacks by analyzing useraccess patterns and recommending intelligentapplication segmentation policies to limitlateral risk. For example, its common tosee that only 200 users out of 30,000with access to a finance application actuallyneed it. Zscaler can automatically create anapplication segment that limits access to onlythose 200 employees, reducing threat actorslateral movement opportunities by morethan 99%.Stage 4:Data exfiltrationSummary of Zscalers
AI\-infused offeringsZscaler Internet Access provides AI\-poweredprotection for enterprise users, devices, and web andSaaS applications across all locations as part of the ZeroTrust Exchange, delivering:AI\-powered phishing and C2 detection against never\-
before\-seen phishing sites and C2 infrastructure, usingM ORE OVE R,ZSCALE RB LO C KS :URLs and IPs observed in the Zscaler cloud as well as natively 
integrated open source and commercial threat intel sources.This includes policy\-defined, high\-risk URL categoriescommonly used for phishing, such as newly observed andnewly activated domains.IPS signatures developed from ThreatLabz analysis of phishing 
kits and pages.Zscaler Risk360 delivers a comprehensive and actionable riskinline AI\-based detection from the Zscaler Secure Webframework that helps security and business leaders to quantifyGateway (SWG).and visualize cyber risk across the enterprise.AI\-powered sandboxing with comprehensive malwareand zero\-day threat prevention.Dynamic, risk\-based policy with continuous analysis 
of user, device, application, and content risk to fueldynamic security and access policy.AI\-powered segmentation with ZscalerPrivate Access, with automated access policyrecommendations to minimize the attack surface andstop lateral movement using user context, behavior,location, location, and private app telemetry.Data Protection with DLP and CASB delivers AI\-powered dataclassification and data protection across all channels, includingendpoint, email, workloads, BYOD, and cloud posture.Advanced Threat Protection blocks all known C2 domains.Zscaler ITDR (Identity Threat Detection and Response)mitigates the risk of identity\-based attacks without ongoingvisibility, risk monitoring, and threat detection.Zscaler Firewall extends C2 protection to all ports andprotocols, including emerging C2 destinations.In the final stage of an attack, threat actorsAI\-powered browser isolation, which creates a safe gapDNS Security defends against DNS\-based attacks andwork to exfiltrate sensitive data. Zscalerbetween users and malicious web categories, renderingexfiltration attempts.uses AI to allow organizations to deploy datacontent as a stream of picture\-perfect images toprotections more quickly. AI\-driven dataeliminate data leaks and delivery of active threats.discovery eliminates the time\-consuming taskof data fingerprinting and classification, whichcan otherwise delay or prevent deployment.Zscaler AI automatically discovers andclassifies all data across an organizationright out of the box, enabling enterprises toimmediately classify sensitive informationwhile configuring Data Loss Prevention (DLP)policies to prevent that data from ever leaving 
the organization in an attack or breach.Zscaler Private Access safeguards applications by limitinglateral movement with least\-privileged access, user\-to\-appsegmentation, and full inline inspection of private app traffic.AppProtection with Zscaler Private Access provides high\-performance, inline security inspection of the entire applicationpayload to expose threats.Zscaler Deception detects and contains attackers attemptingto move laterally or escalate privileges by luring them withdecoy servers, applications, directories, and user accounts.0352024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024HOW ZSCALER DELIVERS AI \+ ZERO TRUST AND SECURES GENERATIVE AIEnabling the enterprise AI transition: 
control is in your handsZscaler provides a way for enterprises to foster innovation, creativity, and productivitywith AI applications while keeping users and data safe among emerging channels for dataexfiltration. This empowers enterprises to embrace the transformative potential of AI toaccelerate their business without outright blocking AI applications and domains.Securing the use of AIML appsAI AppsCompany\-wide visibility of AI app usageAI APP Risk scoring for security \& privacySelective access controls
AIML URL Category \- 3200\+ domain, 100\+Cloud AppsPrevent Data Loss to Generative AI AppsInline DLP: Blocks IP, PII, etc. from leaking out (ChatGPT Prompts)
Remote Browser Isolation: restrict uploads, downloads,
clipboard controlsFIGURE 23 Zscaler delivers innovative, fine\-tuned security 
controls designed for enterprise AIZ SCALE RE NABLE SE NTERPRISE STO :01Drive full visibility into AI tool usage 
01Detailed logs provide complete visibility into how enterprise teams are using AI,including the applications and domains theyre visiting as well as the data and promptsbeing used in tools like ChatGPT.02Create flexible policies to fine\-tune the use of AI 
02Powerful, tailored URL filtering for AI and ML applications let enterprises easilydefine and enforce granular AI access controls and segmentationblocking accesswhen necessary, while allowing access with acceptable levels of risk using AI AppRisk Scoring. Enterprises can allow access at the enterprise, department, team, anduser levels as well as enable caution\-based access that coaches users on the risks ofgenerative AI tools. AI\-driven segmentation makes it easy to identify appropriate usersegments for access to particular AI applications while minimizing the internal attacksurface associated with AI tools.03Enforce granular data security for ChatGPT and other AI applications 
03Enterprises can prevent the leakage of sensitive data uploaded to AI applications withgranular Zscaler Cloud Application controls for generative AI. By enforcing the ZscalerDLP engine, enterprises can ensure that no data is accidentally shared when using anyAI tool. Meanwhile, AI\-powered data discovery and classification lets enterprises easily 
identify and create DLP policies around their most critical data, including their corporatecode base, financial and legal documents, personal data, customer data, and more.This video demonstrates how the DLP engine prevents users from inputting credit cardinformation into ChatGPT.04Enable powerful controls using Browser Isolation 
04Zscaler Browser Isolation renders AI applications in a secure environment, adding a layerof protection that allows user prompts and queries to AI tools while restricting copypaste, uploads, and downloads. This helps mitigate the risk of sensitive data beingaccidentally shared with generative AI tools.Enterprise and security leaders are at a crossroads: they must work to embrace AI to drive 
innovation and stay competitive, but they must also ensure that their data only powersthe business, not breaches. Zscaler empowers enterprises to navigate this transition withconfidence, leveraging a full\-suite of AI\-powered zero trust security controls that protectagainst AI\-driven attacks while offering fine\-tuned AI policies and data protections required 
to harness the full potential of generative AI.0362024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024AppendixThreatLabz research 
methodologyThe Zscaler global security cloud processes over 300 trillion daily signals andblocks 9 billion threats and policy violations per day, with over 250,000 dailysecurity updates. Analysis of 18\.09 billion AI and ML transactions from April2023 to January 2024 in the Zscaler cloud, the Zero Trust Exchange.About Zscaler 
ThreatLabzThreatLabz is the security research arm of Zscaler. This world\-class team is responsiblefor hunting new threats and ensuring that the thousands of organizations using the globalZscaler platform are always protected. In addition to malware research and behavioralanalysis, team members are involved in the research and development of new prototypemodules for advanced threat protection on the Zscaler platform, and regularly conductinternal security audits to ensure that Zscaler products and infrastructure meet securitycompliance standards. ThreatLabz regularly publishes in\-depth analyses of new and 
emerging threats on its portal, research.zscaler.com.0372024 Zscaler, Inc. All rights reserved.ZSCALER THREATLABZ REPORT 2024Experience your world, secured.About Zscaler 
Zscaler (NASDAQ: ZS) accelerates digital transformation so that customers can be more agile, efficient, resilient, and secure. The 
Zscaler Zero Trust Exchange protects thousands of customers from cyberattacks and data loss by securely connecting users, 
devices, and applications in any location. Distributed across more than 150 data centers globally, the SASEbased Zero Trust 
Exchange is the worlds largest inline cloud security platform. To learn more, visit www.zscaler.com. 2024 Zscaler, Inc. All rights reserved. Zscaler, Zero Trust Exchange, Zscaler 
Internet Access, ZIA, Zscaler Private Access, ZPA and other trademarks listed 
at zscaler.comlegaltrademarks are either (i) registered trademarks or service marks 
or (ii) trademarks or service marks of Zscaler, Inc. in the United States andor other 
countries. Any other trademarks are the properties of their respective owners.\+1 408\.533\.0288Zscaler, Inc. (HQ)120 Holger WaySan Jose, CA 95134zscaler.com